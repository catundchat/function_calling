{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 互动教程：用OpenAI的GPT模型进行function calling\n",
    "\n",
    "在这个笔记本中，我们将深入研究OpenAI最新版本的GPT模型（如gpt-3.5-turbo-0613和gpt-3.5-turbo-16k-0613）所提供的一个强大功能：function calling 函数调用。\n",
    "\n",
    "让我们想象一下，你正在和一个ChatGPT模型对话，你想让它使用一个工具。传统上，你必须做一些巧妙的提示才能让它返回你想要的格式。现在你可以告诉它某些动作，或**\"function\"**，它可以产生一些响应，这并不意味着助手实际执行了这些动作。相反，它知道这些动作，并可以根据手头的对话指示你如何执行这些动作。例如，你可以告诉助手一个获取天气数据的函数，当被问及\"成都的天气如何?\"时，GPT模型以\"成都\"作为输入来调用这个获取天气的函数。\n",
    "\n",
    "**function calling**使我们能够利用模型的自然语言理解，有效地将人类语言转化为结构化数据或我们代码中的具体函数调用。这种能力在众多场景中都很有用，从创建可以与其他API互动的聊天机器人，到自动化任务和从自然语言输入中提取结构化信息。[function calling的官方文档](https://platform.openai.com/docs/guides/gpt/function-calling)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先导入所需的package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.0.200 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.0.200)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (2.0.16)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (0.5.8)\n",
      "Requirement already satisfied: langchainplus-sdk>=0.0.9 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (0.0.10)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (1.23.3)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (2.28.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain==0.0.200) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.200) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.200) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.200) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.200) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.200) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.200) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.200) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.200) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.200) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<2,>=1->langchain==0.0.200) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langchain==0.0.200) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langchain==0.0.200) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langchain==0.0.200) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.200) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.200) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\yyyyy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.200) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.0.200\n",
    "# %pip install langchain --upgrade\n",
    "# Version: 0.0.199 Make sure you're on the latest version because this version supports the new release of OpenAI's function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load envrionment variables\n",
    "load_dotenv()\n",
    "\n",
    "# first setup your OpenAI API key as an environment variable\n",
    "# openai.api_key = os.getenv('YOURAPIKEY')\n",
    "openai.api_key = 'youropenaikey'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI 示例\n",
    "\n",
    "我们这里给出调用一下参数定义的天气函数的效果，你可以自己尝试调用其他函数。\n",
    "\n",
    "* **Name：** 这是函数的标识符或名称。\n",
    "* **Description：** 这是对函数功能的简洁说明。模型将依赖此描述来确定何时应调用此函数。\n",
    "* **Parameters：** 参数对象包含函数需要的所有输入字段。这些输入可能的类型包括：字符串（String）、数字（Number）、布尔值（Boolean）、对象（Object）、空值（Null）等等。\n",
    "* **Required：** 在进行查询时必须提供的参数。未在此列表中的参数视为可选项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "            {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and province, e.g. Chengdu, Sichuan\",\n",
    "                        },\n",
    "                        \"unit\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"location\", \"unit\"],\n",
    "                },\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后让我们用这个作为一个新的参数来调用OpenAI的API。注意：确保使用一个可以接受函数调用的模型。这里我们使用`gpt-3.5-turbo-16k-0613`，让我们首先设置一个来自用户的查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What's the weather like in Chengdu?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后让我们设置我们对OpenAI的API调用。注意：`function_call=\"auto\"`将允许模型选择是否用一个函数来响应。如果你不想要一个function calling，你可以把它设置为`none`,OpenAI官方给出的response接口函数如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k-0613\",\n",
    "        \n",
    "        # This is the chat message from the user\n",
    "        messages=[{\"role\": \"user\", \"content\": user_query}],\n",
    "    \n",
    "        functions=function_descriptions,\n",
    "        function_call=\"auto\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"arguments\": \"{\\n  \\\"location\\\": \\\"Chengdu, Sichuan\\\",\\n  \\\"unit\\\": \\\"celsius\\\"\\n}\",\n",
      "    \"name\": \"get_current_weather\"\n",
      "  },\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ai_response_message = response[\"choices\"][0][\"message\"]\n",
    "print(ai_response_message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上为我们的response，并指出了具体的arguments,但还是需要将response整理成我们想要的格式。所以我们要设定好location与unit，然后创建API call的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location = eval(ai_response_message['function_call']['arguments']).get(\"location\")\n",
    "user_unit = eval(ai_response_message['function_call']['arguments']).get(\"unit\")\n",
    "\n",
    "def get_current_weather(location, unit):\n",
    "    \n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    \n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"25\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\", \"cloudy\", \"rainy\", \"snowy\", \"stormy\", \"foggy\", \"hail\",\"sleet\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"Chengdu, Sichuan\", \"temperature\": \"25\", \"unit\": \"celsius\", \"forecast\": [\"sunny\", \"windy\", \"cloudy\", \"rainy\", \"snowy\", \"stormy\", \"foggy\", \"hail\", \"sleet\"]}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_response = get_current_weather(\n",
    "    location=user_location,\n",
    "    unit=user_unit,\n",
    ")\n",
    "\n",
    "function_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经有了从服务器获得的回答，可以将其传递回模型，以获得自然语言的回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Chengdu is 25°C and it is sunny.\n"
     ]
    }
   ],
   "source": [
    "second_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "        ai_response_message,\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": function_response,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print (second_response['choices'][0]['message']['content'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain 对 function calling 的支持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
    "from langchain.tools import format_tool_to_openai_function, YouTubeSearchTool, MoveFileTool\n",
    "\n",
    "# load the model you choose\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k-0613\", openai_api_key=\"YOUROPENAIKEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们加载我们的工具，然后将它们转换成OpenAI的函数框架，并且查看转换结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'move_file',\n",
       "  'description': 'Move or rename a file from one location to another',\n",
       "  'parameters': {'title': 'FileMoveInput',\n",
       "   'description': 'Input for MoveFileTool.',\n",
       "   'type': 'object',\n",
       "   'properties': {'source_path': {'title': 'Source Path',\n",
       "     'description': 'Path of the file to move',\n",
       "     'type': 'string'},\n",
       "    'destination_path': {'title': 'Destination Path',\n",
       "     'description': 'New path for the moved file',\n",
       "     'type': 'string'}},\n",
       "   'required': ['source_path', 'destination_path']}}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [MoveFileTool()]\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "\n",
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.200'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = llm.predict_messages([HumanMessage(content='move file /yubo/ubuntu to /yubo/windows')], functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'move_file',\n",
       " 'arguments': '{\\n  \"source_path\": \"/yubo/ubuntu\",\\n  \"destination_path\": \"/yubo/windows\"\\n}'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.additional_kwargs['function_call']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 金融财务预测用例"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我将创建一个用例来更新金融模型，函数中需要的三个参数分别是 year to update, category to update and amount to update. 我们可以看到，这里的函数调用是一个很好的方式来更新金融模型，而不是直接用自然语言来描述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "            {\n",
    "                \"name\": \"edit_financial_forecast\",\n",
    "                \"description\": \"Make an edit to a users financial forecast model\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"year\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"The year the user would like to make an edit to their forecast for\",\n",
    "                        },\n",
    "                        \"category\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The category of the edit a user would like to edit\"\n",
    "                        },\n",
    "                        \"amount\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"The amount of units the user would like to change\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"year\", \"category\", \"amount\"],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"print_financial_forecast\",\n",
    "                \"description\": \"Send the financial forecast to the printer\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"printer_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"the name of the printer to send the forecast to\",\n",
    "                            \"enum\": [\"home_printer\",\"office_printer\"]\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"printer_name\"],\n",
    "                },\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在函数已经创建好了，我们要来验证OpenAI function calling更新中的LLM调用部分：很有趣的是，是由LLM自己做出选择：1.返回用户一个正常的response；2.或者是使用函数调用 function calling 功能。我们将在同一个用户提问中，给出不同的要求，看看LLM是如何选择的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"\"\"\n",
    "Please do three things add 23 units to 2023 current headcount\n",
    "and subtract 51 units from 2022 opex\n",
    "then print out the forecast at my home\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们要自己跟踪消息的历史。随着对函数对话的支持越来越多，我们就不需要这样做了。首先，我们将把用户的消息和我们的函数调用一起发送给LLM，创建第一个回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'edit_financial_forecast', 'arguments': '{\\n  \"year\": 2023,\\n  \"category\": \"current_headcount\",\\n  \"amount\": 23\\n}'}}, example=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_response = llm.predict_messages([HumanMessage(content=user_request)],\n",
    "                                      functions=function_descriptions)\n",
    "first_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们得到了一个content为空的AIMessage信息，然而有一些additional_kwargs包含了我们需要的信息，我们可以将其提取出来。其中 args 指代 arguments 是位置参数， kwargs 指代 keyword arguments 是关键词参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'name': 'edit_financial_forecast',\n",
       "  'arguments': '{\\n  \"year\": 2023,\\n  \"category\": \"current_headcount\",\\n  \"amount\": 23\\n}'}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show kwargs\n",
    "first_response.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edit_financial_forecast'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show function name, here is edit_financial_forecast\n",
    "function_name = first_response.additional_kwargs[\"function_call\"][\"name\"]\n",
    "function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Year: 2023\n",
      "Category: current_headcount\n",
      "Amount: 23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show defined parameters, here is year, category, amount\n",
    "print (f\"\"\"\n",
    "Year: {eval(first_response.additional_kwargs['function_call']['arguments']).get('year')}\n",
    "Category: {eval(first_response.additional_kwargs['function_call']['arguments']).get('category')}\n",
    "Amount: {eval(first_response.additional_kwargs['function_call']['arguments']).get('amount')}\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们看用户查询中的第二个请求，让我们将其传回模型，创建第二个回答，更新2023年增加的人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_response = llm.predict_messages([HumanMessage(content=user_request),\n",
    "                                        AIMessage(content=str(first_response.additional_kwargs)),\n",
    "                                        ChatMessage(role='function',\n",
    "                                                    additional_kwargs = {'name': function_name},\n",
    "                                                    content = \"Just updated the financial forecast for year 2023, category headcount amd amount 23\"\n",
    "                                                   )\n",
    "                                       ],\n",
    "                                       functions=function_descriptions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查其输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'name': 'edit_financial_forecast',\n",
       "  'arguments': '{\\n  \"year\": 2022,\\n  \"category\": \"opex\",\\n  \"amount\": -23\\n}'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_response.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edit_financial_forecast'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_name = second_response.additional_kwargs['function_call']['name']\n",
    "function_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM看到第一个响应已经完成，然后返回到我们的函数edit_financial_forecast中。让我们看看如果我们第三次这样做，LLM会返回什么回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_response = llm.predict_messages([HumanMessage(content=user_request),\n",
    "                                       AIMessage(content=str(first_response.additional_kwargs)),\n",
    "                                       AIMessage(content=str(second_response.additional_kwargs)),\n",
    "                                       ChatMessage(role='function',\n",
    "                                                    additional_kwargs = {'name': function_name},\n",
    "                                                    content = \"\"\"\n",
    "                                                        Just made the following updates: 2022, opex -51 and\n",
    "                                                        Year: 2023\n",
    "                                                        Category: headcount\n",
    "                                                        Amount: 51\n",
    "                                                    \"\"\"\n",
    "                                                   )\n",
    "                                       ],\n",
    "                                       functions=function_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'name': 'print_financial_forecast',\n",
       "  'arguments': '{\\n  \"printer_name\": \"home_printer\"\\n}'}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_response.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print_financial_forecast'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_name = third_response.additional_kwargs['function_call']['name']\n",
    "function_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们看到LLM知道它已经完成了财务预测，然后自动选择了print_financial_forecast并将我们的回答作为输入。\n",
    "现在我们提出第四个请求，命令其用home_printer打印财务报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "forth_response = llm.predict_messages([HumanMessage(content=user_request),\n",
    "                                       AIMessage(content=str(first_response.additional_kwargs)),\n",
    "                                       AIMessage(content=str(second_response.additional_kwargs)),\n",
    "                                       AIMessage(content=str(third_response.additional_kwargs)),\n",
    "                                       ChatMessage(role='function',\n",
    "                                                    additional_kwargs = {'name': function_name},\n",
    "                                                    content = \"\"\"\n",
    "                                                        just printed the document at home\n",
    "                                                    \"\"\"\n",
    "                                                   )\n",
    "                                       ],\n",
    "                                       functions=function_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forth_response.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have added 23 units to the current headcount forecast for 2023 and subtracted 51 units from the opex forecast for 2022. The financial forecast has been printed at your home.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forth_response.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们看到，对于第四次回答，LLM没有使用function calling功能（kwargs参数返回空值），而是直接返回了一个response。这是因为LLM认为这个response是一个更好的回答，而不是使用function calling功能。所以，LLM在选择是否使用function calling功能时，是有自己的判断标准的，而不是我们自己的判断标准。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
